{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prad69/NLP/blob/main/NLP_Word_and_Sentence_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ki6jcwCjGwk1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo4S8f58Gwk9"
      },
      "source": [
        "# Word Embeddings\n",
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yYyDkHMSGwk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5ef615-dce6-4a0f-f452-52f54dd89e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "# First, you'll need to install gensim\n",
        "!pip install gensim\n",
        "\n",
        "# Import the necessary modules\n",
        "\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0FCHyZ0GwlB",
        "outputId": "0cd84126-f12a-45aa-8302-077208ba2a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
          ]
        }
      ],
      "source": [
        "print(common_texts) #Sample Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obAnQvieGwlE"
      },
      "source": [
        " Word2vec accepts several parameters that affect both training speed and quality.\n",
        "\n",
        "One of them is for pruning the internal dictionary. Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there’s not enough data to make any meaningful training on those words, so it’s best to ignore them:\n",
        "1\n",
        "\n",
        "model = Word2Vec(sentences, min_count=10)  # default value is 5\n",
        "\n",
        "A reasonable value for min_count is between 0-100, depending on the size of your dataset.\n",
        "\n",
        "Another parameter is the size of the NN layers, which correspond to the “degrees” of freedom the training algorithm has:\n",
        "1\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=200)  # default value is 100\n",
        "\n",
        "Bigger size values require more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other hyper-parameters:\n",
        "\n",
        "*   size: window=window_size for capturing context for target word\n",
        "\n",
        "*   sample: The threshold for configuring which higher-frequency words are randomly down sampled, useful range is (0, 1e-5)\n",
        "\n",
        "*   workers: Use these many worker threads to train the model (faster training with multicore machines)\n",
        "\n",
        "*   sg: Training algorithm: skip-gram if sg=1, otherwise CBOW.\n",
        "\n",
        "*   iter: Number of iterations (epochs) over the corpus.\n"
      ],
      "metadata": {
        "id": "eHJa7t_dVlNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "enTdB5hPGwlH"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences=common_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "#Here, vector_size = 10 denotes the length of embedding\n",
        "model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiL5GEqaGwlJ"
      },
      "source": [
        "If you save the model you can continue training it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EVn5-eMTGwlK"
      },
      "outputs": [],
      "source": [
        "# load the saved model\n",
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "# model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcwKsP0OGwlM"
      },
      "source": [
        "The trained word vectors are stored in a KeyedVectors instance, as model.wv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LQ-S-El4GwlO",
        "outputId": "eef11dda-8236-452b-c0e5-dc6310541e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00410223 -0.08368949 -0.05600012  0.07104538  0.0335254   0.0722567\n",
            "  0.06800248  0.07530741 -0.03789154 -0.00561806]\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Get the embeddings for the word 'human'\n",
        "embedding = model.wv['human']\n",
        "\n",
        "print(embedding)\n",
        "print(len(embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2zWtQqtrGwlP",
        "outputId": "a1b9a984-d661-49d2-abc4-818c1bf484e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('graph', 0.3586882948875427), ('system', 0.22743132710456848), ('time', 0.1153423935174942)]\n"
          ]
        }
      ],
      "source": [
        "# Get the most similar words (having the most similar embeddings)\n",
        "similar_words = model.wv.most_similar('human',topn = 3) #topn denotes the top 3 similar words\n",
        "print(similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NrllmXJqGwlR"
      },
      "outputs": [],
      "source": [
        "# Store just the words + their trained embeddings.\n",
        "word_vectors = model.wv\n",
        "word_vectors.save(\"word2vec.wordvectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PFj9xhGgGwlS",
        "outputId": "f6687d27-89ab-497a-a3d6-20f280aae866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0163195 ,  0.00189972,  0.03474648,  0.00217841,  0.09621626,\n",
              "        0.05062076, -0.08919986, -0.0704361 ,  0.00901718,  0.06394394],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load back with memory-mapping = read-only, shared across processes.\n",
        "from gensim.models import KeyedVectors\n",
        "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
        "wv['computer']  # Get numpy vector embedding for 'computer'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hme83l4GwlT"
      },
      "source": [
        "### Refer to the link below for more details:\n",
        "https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM6M_oYAGwlU"
      },
      "source": [
        "# Gensim comes with several already pre-trained models, in the Gensim-data repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WEvTubVQGwlV",
        "outputId": "f6679024-736b-4a54-abb8-40898cf0c54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "# Show all available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0gl5eMeCGwlV",
        "outputId": "d6ce3bce-a130-422d-b570-f03bb884ba47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7c0a7039ca10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Download the \"glove-twitter-25\" embeddings\n",
        "# Pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased.\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
        "glove_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CcG_GXoUGwlX",
        "outputId": "76fad263-6b71-44c5-f1f9-187ec0c3d3b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('facebook', 0.948005199432373),\n",
              " ('tweet', 0.9403423070907593),\n",
              " ('fb', 0.9342358708381653),\n",
              " ('instagram', 0.9104824066162109),\n",
              " ('chat', 0.8964964747428894),\n",
              " ('hashtag', 0.8885937333106995),\n",
              " ('tweets', 0.8878158330917358),\n",
              " ('tl', 0.8778461217880249),\n",
              " ('link', 0.8778210878372192),\n",
              " ('internet', 0.8753897547721863)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Use the downloaded vectors as usual:\n",
        "glove_vectors.most_similar('twitter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvnW9NgBGwla"
      },
      "source": [
        "# Document/Sentence Embeddings\n",
        "Paragraph, Sentence, and Document embeddings\n",
        "\n",
        "## Doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "If7cxdRzGwlj",
        "outputId": "db8005f7-4336-48c1-8bc6-d555e46281a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Embeddings:\n",
            "[array([ 0.04198869,  0.01253986, -0.04709351, -0.03361204,  0.03727632,\n",
            "        0.0360917 , -0.04976037, -0.01924757,  0.00466516, -0.04645238],\n",
            "      dtype=float32), array([ 0.03795011,  0.04658079,  0.00688064,  0.02874659, -0.01405975,\n",
            "        0.03965318,  0.04835472, -0.03572603, -0.01147622,  0.00996721],\n",
            "      dtype=float32), array([-0.03657199, -0.04226479, -0.00826058, -0.04235109,  0.04691093,\n",
            "       -0.03137154,  0.01618799,  0.03856817,  0.04027783,  0.01325311],\n",
            "      dtype=float32), array([ 0.00235717, -0.01192741,  0.04444199, -0.02232105, -0.01424887,\n",
            "       -0.02587563, -0.02123747, -0.00106649, -0.00531701, -0.01841368],\n",
            "      dtype=float32), array([ 0.02992814,  0.02777706, -0.00993294, -0.03367668, -0.03010589,\n",
            "       -0.001131  , -0.04741756,  0.01215397,  0.03172598, -0.04326031],\n",
            "      dtype=float32)]\n",
            "\n",
            "Shape:\n",
            "(5, 10)\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Define your sentences (example)\n",
        "sentences = [\"this is the first sentence\", \"this is the second sentence\", \"yet another sentence\", \"one more sentence\", \"and the final sentence\"]\n",
        "\n",
        "# Tag the sentences for training\n",
        "tagged_data = [TaggedDocument(words=sentence.split(), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
        "\n",
        "# Train the model\n",
        "model = Doc2Vec(tagged_data, vector_size=10, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Get the embeddings for the sentences\n",
        "sentence_vectors = [model.infer_vector(sentence.split()) for sentence in sentences]\n",
        "# The infer_vectors expects the input as a list of words (nltk.word_tokenize())\n",
        "\n",
        "print(\"Sentence Embeddings:\")\n",
        "print(sentence_vectors) #Embeddings of the sentences\n",
        "\n",
        "import numpy as np\n",
        "print(\"\\nShape:\")\n",
        "print(np.array(sentence_vectors).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bF1RI8k8Gwlk",
        "outputId": "ad937e7a-0582-496f-ce11-ad1f1fc8bfe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04198869,  0.01253986, -0.04709351, -0.03361204,  0.03727632,\n",
              "        0.0360917 , -0.04976037, -0.01924757,  0.00466516, -0.04645238],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sentence_vectors[0] #the first embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-XesFtYhGwll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6d08f3-c009-45f3-ac91-f1188513633d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(-0.6857255)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(sentence_vectors[1].reshape(1,-1),sentence_vectors[2].reshape(1,-1))[0][0]\n",
        "#Cosine similarity between embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0DKoWDb-Gwln",
        "outputId": "55d1b4c8-619c-46a5-8443-0bc3a2411dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.03847909, -0.13069807, -0.12699436,  0.5823946 ],\n",
              "       [-0.03847909,  0.99999994, -0.68572557, -0.4150059 , -0.18280153],\n",
              "       [-0.13069807, -0.68572557,  1.        ,  0.04168017, -0.16783181],\n",
              "       [-0.12699436, -0.4150059 ,  0.04168017,  0.99999994,  0.3402756 ],\n",
              "       [ 0.5823946 , -0.18280153, -0.16783181,  0.3402756 ,  1.0000001 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Find the similarity between all the sentences\n",
        "similarity = cosine_similarity(sentence_vectors)\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H_8s2ff2Gwlo",
        "outputId": "cd80b9e8-dfce-4266-96f4-5537b7aa3240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence --> this is the first sentence\n",
            "Most Similar Sentence --> and the final sentence\n",
            "Cosine Simialrity: 0.58239454\n"
          ]
        }
      ],
      "source": [
        "#Find the most similar sentence to the first sentence (at index = 0)\n",
        "ind = 0  # The index of the sentence for which you want to find the most similar sentence\n",
        "max = -1 # This will store the cosine_similarity of the most similar document\n",
        "print(\"Input Sentence -->\", sentences[ind])\n",
        "for i in range(np.array(sentence_vectors).shape[0]):\n",
        "    if i != ind:\n",
        "        if max < cosine_similarity(sentence_vectors[i].reshape(1,-1),sentence_vectors[ind].reshape(1,-1))[0][0]:\n",
        "            max = cosine_similarity(sentence_vectors[i].reshape(1,-1),sentence_vectors[ind].reshape(1,-1))[0][0]\n",
        "            s_ind = i\n",
        "\n",
        "print(\"Most Similar Sentence -->\", sentences[s_ind])\n",
        "print(\"Cosine Simialrity:\", max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZynnc0BGwlp"
      },
      "source": [
        "#### More about Doc2vec here:\n",
        "https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}